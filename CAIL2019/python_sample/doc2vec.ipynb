{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim import utils\n",
    "# random\n",
    "import random\n",
    "\n",
    "# numpy\n",
    "import re\n",
    "import numpy\n",
    "import gensim, logging\n",
    "import os\n",
    "import jieba\n",
    "import json\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import  LinearSVC\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(line):\n",
    "    #剔除日期\n",
    "    data_regex = re.compile(u\"\"\"        #utf-8编码\n",
    "        年 |\n",
    "        月 |\n",
    "        日 |\n",
    "        (周一) |\n",
    "        (周二) | \n",
    "        (周三) | \n",
    "        (周四) | \n",
    "        (周五) | \n",
    "        (周六)\n",
    "    \"\"\", re.VERBOSE)\n",
    "    #剔除所有数字\n",
    "    decimal_regex = re.compile(r\"[^a-zA-Z]\\d+\")\n",
    "\n",
    "    line = data_regex.sub(r\"\", line)\n",
    "    line = decimal_regex.sub(r\"\", line)\n",
    "\n",
    "    return line\n",
    "\n",
    "def trans(sentence,cutwordslist = None):\n",
    "    texts_cut = [word for word in jieba.lcut(filter(sentence)) if len(word) > 1]\n",
    "    outstr = ' '.join(texts_cut)\n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTxt():\n",
    "    se = set()\n",
    "    f = open(\"../input/input.txt\", \"r\", encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        x = json.loads(line)\n",
    "        se.add(x[\"A\"])\n",
    "        se.add(x[\"B\"])\n",
    "        se.add(x[\"C\"])\n",
    "        \n",
    "    new_file = open(\"../input/new_input.txt\", 'a',encoding=\"utf8\")\n",
    "    cutwordslist = []\n",
    "    data = list(se)\n",
    "    for a in range(0, len(data)):\n",
    "        data[a] = trans(data[a],cutwordslist)\n",
    "        \n",
    "        \n",
    "        #打开fie_name路径下的my_infor.txt文件,采用追加模式\n",
    "        #若文件不存在,创建，若存在，追加\n",
    "        new_file.write(data[a] + '\\n')\n",
    "    new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/8j/p8231m8944s1l43bpl8h5t780000gn/T/jieba.cache\n",
      "Loading model cost 0.671 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "saveTxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggedLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "        flipped = {}\n",
    "        self.tagToText = dict()\n",
    "\n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "\n",
    "    def __iter__(self):\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    yield TaggedDocument(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
    "\n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    text = utils.to_unicode(line).split()\n",
    "                    tag = prefix + '_%s' % item_no\n",
    "                    self.sentences.append(TaggedDocument(text, [tag]))\n",
    "                    self.tagToText[tag] = text\n",
    "        return(self.sentences)\n",
    "\n",
    "    def sentences_perm(self):\n",
    "        shuffled = list(self.sentences)\n",
    "        random.shuffle(shuffled)\n",
    "        return(shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = {'../input/new_input.txt':'TRAIN'}\n",
    "\n",
    "sentences = TaggedLineSentence(sources)\n",
    "model = Doc2Vec(min_count=1, window=5, vector_size=300, sample=1e-4, negative=5, workers=7)\n",
    "model.build_vocab(sentences.to_array())\n",
    "model.train(sentences.sentences_perm(), epochs=500, total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('同期', 0.3399195075035095),\n",
       " ('按分', 0.27054232358932495),\n",
       " ('房地产', 0.27041709423065186),\n",
       " ('一切', 0.2581440210342407),\n",
       " ('建筑', 0.25032883882522583),\n",
       " ('以上', 0.24582038819789886),\n",
       " ('连带责任', 0.24567046761512756),\n",
       " ('嘉合', 0.23965546488761902),\n",
       " ('特此', 0.22511425614356995),\n",
       " ('暨阳', 0.2226559817790985)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('贷款')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24723788, -0.2669648 ,  0.52133167,  0.04069306,  0.05110539,\n",
       "        1.3481535 ,  0.36120468, -0.5461391 ,  0.07782156, -0.30396992,\n",
       "       -0.25895113,  0.39769256,  0.48989594,  0.01740984,  0.88850015,\n",
       "        0.3721652 , -0.40815273,  0.10338775,  0.6010039 ,  0.13516295,\n",
       "        0.76315945,  0.0016245 ,  0.51331794,  0.04475264,  0.2412806 ,\n",
       "        0.6342639 ,  0.6985495 ,  0.9689609 ,  0.30470052, -0.33417118,\n",
       "        0.06756281,  0.09594025,  0.50065637, -0.50017506,  0.83391696,\n",
       "       -0.54454964, -1.0243362 ,  0.18816279, -0.11972433,  0.20329353,\n",
       "       -0.38969728,  0.84276843,  0.53447324,  1.0577382 , -0.4552966 ,\n",
       "       -0.5803535 , -0.03164423,  0.39466655,  0.40108457,  0.39115265,\n",
       "        0.2858232 ,  1.0854676 , -0.9312225 ,  0.65878797, -0.37902713,\n",
       "        0.68307203,  0.4871506 , -0.14926112,  0.3415158 ,  0.48316178,\n",
       "       -0.14005838, -0.76269644, -0.39544892, -0.59608567,  0.337287  ,\n",
       "        0.40987593, -0.30730993,  0.49860027,  0.32741287, -0.1256278 ,\n",
       "       -1.0564972 , -0.11329282, -1.0601089 , -0.42753708,  0.1198287 ,\n",
       "        0.40900522, -0.06818093, -0.07009273,  0.10346331, -0.18917136,\n",
       "        0.02575853,  0.29833394,  0.34482598,  0.01139245,  0.12499037,\n",
       "        0.2849863 , -0.20551862, -0.40441933, -0.33717245,  0.75898737,\n",
       "        0.22071874,  0.04102391,  1.3111321 ,  0.7216242 ,  0.46406236,\n",
       "       -0.5711671 , -0.3231117 , -0.58892095,  0.86513793, -0.05171571,\n",
       "        0.6276867 ,  0.58551955, -0.02947553, -0.1703586 , -0.55524516,\n",
       "       -0.08583864, -0.26997417, -0.24256974, -0.4657383 , -1.1402572 ,\n",
       "        0.91530573, -0.08094943, -0.4245672 ,  1.374257  , -0.90805686,\n",
       "        0.06450091,  1.0427074 ,  0.37263122, -0.05131112, -0.26455063,\n",
       "        1.1050569 ,  0.40544832, -0.60955185, -1.1007032 ,  0.69738007,\n",
       "       -0.7358904 ,  0.01692707,  0.79113936,  0.08043054, -0.90767753,\n",
       "       -0.15341584, -0.1937986 , -0.11431128,  0.75334114,  0.20431824,\n",
       "       -0.226338  ,  0.857593  , -0.81916875, -0.37056416,  0.05529992,\n",
       "       -0.05807041, -0.07149954,  0.38968042, -0.61528516, -0.25186896,\n",
       "       -0.6701847 , -0.01617662, -0.2533339 ,  1.3033689 ,  0.37566325,\n",
       "       -0.01921921,  0.8834456 , -1.3072296 , -0.17145878,  0.21055193,\n",
       "        0.11502542,  0.64776623,  0.63884574, -0.5732206 ,  0.4256216 ,\n",
       "        0.9494043 , -0.42286396,  0.51485544,  0.39101082,  0.7763628 ,\n",
       "        0.24728371,  0.04675405,  0.5824898 ,  0.9106707 , -1.1898756 ,\n",
       "        0.11120363,  0.67794347, -0.19850297, -0.56440854, -1.5654588 ,\n",
       "       -1.0647289 , -0.2611971 , -0.7383104 , -1.1608142 , -0.5385299 ,\n",
       "       -0.43670237, -1.0990596 ,  0.14524788, -0.25345445,  0.72839874,\n",
       "        1.0560384 ,  0.60578394,  0.16533267, -0.9229064 ,  0.12051518,\n",
       "       -0.3207286 , -0.8177496 , -0.0088459 ,  0.48621765,  0.39504772,\n",
       "       -0.11790632,  0.68293035,  0.6629972 ,  0.5537377 ,  0.5850405 ,\n",
       "       -0.2720678 , -0.07654098,  0.7924637 , -0.1047693 , -0.3566794 ,\n",
       "       -0.3079479 , -0.6796602 ,  1.0862867 , -1.0321475 , -0.6025147 ,\n",
       "        0.8805762 , -0.81625   , -0.5206064 ,  0.37326914,  0.20403178,\n",
       "        0.5251613 ,  0.39521366, -0.29773232,  0.08402928, -0.54647624,\n",
       "        0.62763774, -0.26308006, -0.77648675, -0.5249209 , -0.6597571 ,\n",
       "       -0.5560144 , -0.20439869,  0.4496526 , -0.33120698, -0.11054729,\n",
       "       -0.5758951 ,  0.01562566,  0.06592789, -0.597599  , -0.18250148,\n",
       "       -0.6882082 , -0.5005296 ,  0.4871665 , -0.25794047, -0.40409225,\n",
       "       -0.561829  ,  0.93255496, -0.37837085,  1.1421244 , -0.51383424,\n",
       "       -0.14711845, -0.567988  ,  0.3773618 ,  0.42434543,  0.22353199,\n",
       "       -0.38847017, -0.5781133 ,  0.01005735, -0.41353375,  0.24129055,\n",
       "        0.2466278 ,  0.07502136,  0.53979516,  0.52967113, -0.32810238,\n",
       "        0.8497803 ,  0.4856174 , -0.6827709 ,  0.62828624, -0.6070656 ,\n",
       "       -0.48965153,  0.275662  , -0.08132061, -0.9840122 , -0.78486955,\n",
       "       -1.186458  , -0.13447675,  0.5930349 ,  0.11530607, -0.28874978,\n",
       "        0.07190565,  0.36490947, -0.6783917 ,  1.0441244 , -0.34333763,\n",
       "       -0.28616178, -1.6094921 ,  0.2490144 ,  0.6558807 ,  0.5479406 ,\n",
       "        1.1409142 ,  0.04014145, -0.4906248 ,  0.7800861 ,  0.84280235,\n",
       "       -0.3262016 , -0.12425322,  0.77398574, -1.2389035 ,  0.7891432 ,\n",
       "       -0.16656248,  0.02435873, -0.60397583,  0.15278699, -1.0202485 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_train_pos = 'TRAIN_' + str(0)\n",
    "model[prefix_train_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原告 出生 汉族 农民 蒲城县 山镇 被告 出生 汉族 农民 蒲城县 山镇 原告 屈向 本院 提出 诉讼请求 请求 判令 被告 立即 清偿 原告 借款 本元及 利息 按利 计算 清偿 案件 受理费 被告 承担 事实 理由 被告 同村 村民 被告 安以 生意 资金周转 困难 原告 借元 双方 口头 约定 借款 期限 借款 到期 被告 并未 履行 还款 义务 被告 安未作 答辩 原告 支持 主张 本院 提供 被告 署名 借条 一张 屈晓辉 证人 证言 用以 证明 被告 原元 事实 被告 安未 提供 证据 被告 安经 传唤 到庭 提供 答辩 质证 意见 视为 自己 质证 权利 放弃 原告 提供 证据 真实 合法 两份 证据 之间 能够 相互 印证 可以 作为 定案 依据 根据 认定 证据 以及 当事人 庭审 陈述 能够 查明 以下 案件 事实 被告 曾系 同事 关系 被告 资金周转 困难 原告 借款 原告 当时 旬阳 尧柏 水泥厂 上班 支付宝 转账 形式 案外人 屈晓辉 转元 委托 屈晓辉 交于 被告 被告 原告 出具 借条 屈晓辉 交于 被告 被告 原告 出具 借条 一张 交由 屈晓辉 内容 借条 今借 屈壹 万元 整元整 身份证号 借款 时未 约定 利息 双方 口头 约定 还款 期限\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(sentences.tagToText[prefix_train_pos]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['原告', '出生', '汉族', '农民', '蒲城县', '山镇', '被告', '出生', '汉族', '农民', '蒲城县', '山镇', '原告', '屈向', '本院', '提出', '诉讼请求', '请求', '判令', '被告', '立即', '清偿', '原告', '借款', '本元及', '利息', '按利', '计算', '清偿', '案件', '受理费', '被告', '承担', '事实', '理由', '被告', '同村', '村民', '被告', '安以', '生意', '资金周转', '困难', '原告', '借元', '双方', '口头', '约定', '借款', '期限', '借款', '到期', '被告', '并未', '履行', '还款', '义务', '被告', '安未作', '答辩', '原告', '支持', '主张', '本院', '提供', '被告', '署名', '借条', '一张', '屈晓辉', '证人', '证言', '用以', '证明', '被告', '原元', '事实', '被告', '安未', '提供', '证据', '被告', '安经', '传唤', '到庭', '提供', '答辩', '质证', '意见', '视为', '自己', '质证', '权利', '放弃', '原告', '提供', '证据', '真实', '合法', '两份', '证据', '之间', '能够', '相互', '印证', '可以', '作为', '定案', '依据', '根据', '认定', '证据', '以及', '当事人', '庭审', '陈述', '能够', '查明', '以下', '案件', '事实', '被告', '曾系', '同事', '关系', '被告', '资金周转', '困难', '原告', '借款', '原告', '当时', '旬阳', '尧柏', '水泥厂', '上班', '支付宝', '转账', '形式', '案外人', '屈晓辉', '转元', '委托', '屈晓辉', '交于', '被告', '被告', '原告', '出具', '借条', '屈晓辉', '交于', '被告', '被告', '原告', '出具', '借条', '一张', '交由', '屈晓辉', '内容', '借条', '今借', '屈壹', '万元', '整元整', '身份证号', '借款', '时未', '约定', '利息', '双方', '口头', '约定', '还款', '期限']\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(sentences.tagToText[prefix_train_pos])\n",
    "tokens = text.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vector = model.infer_vector(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(MODEL_PATH,DOC2VEC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load(os.path.join(MODEL_PATH,DOC2VEC))  # you can continue training with the loaded model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
