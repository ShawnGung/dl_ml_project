{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim import utils\n",
    "# random\n",
    "import random\n",
    "\n",
    "# numpy\n",
    "import numpy\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import  LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggedLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "        flipped = {}\n",
    "        self.tagToText = dict()\n",
    "\n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "\n",
    "    def __iter__(self):\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    yield TaggedDocument(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
    "\n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    text = utils.to_unicode(line).split()\n",
    "                    tag = prefix + '_%s' % item_no\n",
    "                    self.sentences.append(TaggedDocument(text, [tag]))\n",
    "                    self.tagToText[tag] = text\n",
    "        return(self.sentences)\n",
    "\n",
    "    def sentences_perm(self):\n",
    "        shuffled = list(self.sentences)\n",
    "        random.shuffle(shuffled)\n",
    "        return(shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = {'data/test_neg.txt':'TEST_NEG', 'data/test_pos.txt':'TEST_POS', 'data/train_neg.txt':'TRAIN_NEG', 'data/train_pos.txt':'TRAIN_POS'}\n",
    "\n",
    "sentences = TaggedLineSentence(sources)\n",
    " \n",
    "model = Doc2Vec(min_count=1, window=10, vector_size=100, sample=1e-4, negative=5, workers=7)\n",
    "model.build_vocab(sentences.to_array())\n",
    "model.train(sentences.sentences_perm(), epochs=10, total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the most similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.8010649085044861),\n",
       " ('decent', 0.7656506896018982),\n",
       " ('good,', 0.7534111738204956),\n",
       " ('nice', 0.7411749362945557),\n",
       " ('good.', 0.7183130979537964),\n",
       " ('bad', 0.7146064043045044),\n",
       " ('fine', 0.6791468858718872),\n",
       " ('really', 0.661880612373352),\n",
       " ('great,', 0.6555169820785522),\n",
       " ('solid', 0.6400054097175598)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.67604452e-02,  6.85367063e-02,  8.34903643e-02, -8.47806633e-02,\n",
       "        6.58253059e-02,  4.05879766e-02,  5.57096116e-02, -4.13171910e-02,\n",
       "        1.20364886e-03, -1.33396551e-01, -1.40106753e-02,  7.09639564e-02,\n",
       "        1.84043162e-02, -5.35935760e-02,  4.90804464e-02,  7.02047348e-02,\n",
       "        4.91940193e-02,  7.05393553e-02,  2.74535976e-02,  5.42438552e-02,\n",
       "        1.09348230e-01,  5.09758852e-02,  2.62266807e-02, -1.06784329e-02,\n",
       "        2.43218560e-02,  6.12404943e-02,  8.86478424e-02, -1.53240353e-01,\n",
       "        3.61667499e-02,  3.92867699e-02,  2.56076995e-02,  1.80427695e-03,\n",
       "        6.02349080e-02,  2.03826167e-02,  3.46294692e-05, -1.59500074e-02,\n",
       "       -4.92557921e-02, -4.96926531e-02,  3.45059223e-02,  1.88102238e-02,\n",
       "       -4.85540740e-02,  9.30692926e-02,  1.13568008e-01, -5.72237074e-02,\n",
       "        7.36734504e-03, -1.10213488e-01, -2.29404103e-02,  7.66101480e-02,\n",
       "        2.65874937e-02, -5.14724925e-02, -1.13697939e-01,  4.48653921e-02,\n",
       "        2.75861491e-02,  4.60637622e-02, -4.94536646e-02, -6.83422834e-02,\n",
       "       -2.71001440e-02,  3.01810857e-02,  1.06880255e-02, -3.82774882e-02,\n",
       "        7.21717030e-02, -2.37429757e-02, -7.46736154e-02, -3.06300875e-02,\n",
       "       -2.08394565e-02, -9.37610492e-02,  1.55456774e-02,  5.27356267e-02,\n",
       "        8.95344764e-02, -1.45378010e-02,  2.54730694e-03,  3.85909937e-02,\n",
       "       -5.72053939e-02,  3.56760025e-02,  3.21805524e-03,  2.89631169e-02,\n",
       "       -1.09816259e-02, -1.89078995e-03, -1.16684204e-02,  2.45207511e-02,\n",
       "        3.81934992e-03, -1.14833459e-01, -9.91317630e-02,  9.62780043e-02,\n",
       "        8.09095949e-02,  4.26457375e-02,  9.82039236e-03, -2.25433093e-02,\n",
       "       -1.74822565e-02, -1.13794275e-01,  1.22087318e-02,  1.80647019e-02,\n",
       "       -9.15876776e-02, -6.19586185e-03, -5.78034706e-02,  1.44262062e-02,\n",
       "        3.51345912e-02, -1.95057467e-02, -6.45200759e-02, -1.05227903e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['TRAIN_NEG_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./imdb.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Doc2Vec.load('./imdb.d2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do classfication and it can classify 83% correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arrays = numpy.zeros((25000, 100))\n",
    "train_labels = numpy.zeros(25000)\n",
    "\n",
    "for i in range(12500):\n",
    "    prefix_train_pos = 'TRAIN_POS_' + str(i)\n",
    "    prefix_train_neg = 'TRAIN_NEG_' + str(i)\n",
    "    train_arrays[i] = model[prefix_train_pos]\n",
    "    train_arrays[12500 + i] = model[prefix_train_neg]\n",
    "    train_labels[i] = 1\n",
    "    train_labels[12500 + i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04092867  0.05030482  0.01592999 ...  0.0494524   0.08508648\n",
      "  -0.12458809]\n",
      " [-0.06956087  0.53839409  0.29971007 ...  0.1563656  -0.2468898\n",
      "  -0.20472236]\n",
      " [ 0.04621632  0.15324871  0.00701381 ...  0.10775265 -0.07272544\n",
      "  -0.03794105]\n",
      " ...\n",
      " [-0.08181398  0.33077008  0.15650262 ...  0.09846954 -0.19612412\n",
      "  -0.0578531 ]\n",
      " [ 0.0962573   0.40005031  0.12608531 ... -0.06523082 -0.17672288\n",
      "  -0.03303262]\n",
      " [ 0.04914996  0.18799147  0.00920538 ...  0.11031672  0.03501993\n",
      "  -0.0096805 ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arrays = numpy.zeros((25000, 100))\n",
    "test_labels = numpy.zeros(25000)\n",
    "\n",
    "for i in range(12500):\n",
    "    prefix_test_pos = 'TEST_POS_' + str(i)\n",
    "    prefix_test_neg = 'TEST_NEG_' + str(i)\n",
    "    test_arrays[i] = model[prefix_test_pos]\n",
    "    test_arrays[12500 + i] = model[prefix_test_neg]\n",
    "    test_labels[i] = 1\n",
    "    test_labels[12500 + i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver = 'liblinear')\n",
    "classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83612"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the most similar sentences in training s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TRAIN_NEG_1', 0.9999998807907104), ('TEST_NEG_7979', 0.6596706509590149), ('TRAIN_NEG_677', 0.6457411050796509), ('TRAIN_NEG_11997', 0.6352208256721497), ('TRAIN_NEG_2542', 0.6332000494003296), ('TEST_NEG_3255', 0.6267741918563843), ('TEST_NEG_1168', 0.6215671300888062), ('TEST_NEG_8942', 0.6147149801254272), ('TEST_NEG_9452', 0.6145933866500854), ('TEST_NEG_9643', 0.6119739413261414)]\n"
     ]
    }
   ],
   "source": [
    "# 寻找跟train训练集的负面第一条评论的最相像评论\n",
    "sims = model.docvecs.most_similar([model['TRAIN_NEG_1']],topn=10)\n",
    "print(sims)\n",
    "print(sentences.tagToText[sims[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TEST_POS_2868', 0.8263417482376099), ('TRAIN_POS_2462', 0.8107128143310547), ('TRAIN_POS_3098', 0.8102821707725525), ('TRAIN_POS_11410', 0.8099147081375122), ('TEST_POS_5559', 0.8034120202064514), ('TRAIN_POS_1738', 0.803398847579956), ('TEST_POS_4882', 0.8029893040657043), ('TEST_POS_10926', 0.7982553243637085), ('TEST_NEG_340', 0.7977356314659119), ('TEST_NEG_6772', 0.797174334526062)]\n",
      "============new_text:=============\n",
      " I love all the Devilman Crybaby vibes I get from this show!!! It's disturbingly gruesome at times and laugh out loud funny at others. I haven't even watched the entire season but I'm already looking forward to season 2! If you loved Devilman Crybaby or Black Mirror, you'll love this show. If you aren't sure about it, just give it a try because it's honestly so good!!!\n",
      "=========most similar text:=========\n",
      "This film is the best kung fu film of all time. Although there is not wire-work and special effects like those used in Crouching Tiger, this movie uses ingenuity and creative camera-work to create memorable fighting moments, and the fight scenes are well choreographed and tight. There is a ton of action in this film with lots of great fight scenes, but the story is very good too,with lots of twists and turns. The characters are well rounded and have real depth to them, as the motivations for their actions and personality are revealed in a much greater detail than most kung fu films. There is some really great camera-work in the film, with my favorite shot starting as a close up on our hero's face showing his reaction, then pulls back quickly to reveal the scene before him that is the cause of his look. Originally, I bought the movie to hoping see some great fight scenes, but upon multiple viewings I learned how terrific the acting and story were as well. Overall, a great film.\n"
     ]
    }
   ],
   "source": [
    "new_text = \"I love all the Devilman Crybaby vibes I get from this show!!! It's disturbingly gruesome at times and \\\n",
    "laugh out loud funny at others. I haven't even watched the entire season but I'm already looking forward to season 2! \\\n",
    "If you loved Devilman Crybaby or Black Mirror, you'll love this show. If you aren't sure about it, just give it a try because it's honestly so good!!!\"\n",
    "tokens = new_text.split()\n",
    "new_vector = model.infer_vector(tokens)\n",
    "sims = model.docvecs.most_similar([new_vector],topn=10)\n",
    "print(sims)\n",
    "print('============new_text:=============\\n', new_text)\n",
    "print('=========most similar text:=========')\n",
    "print(' '.join(sentences.tagToText[sims[0][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
