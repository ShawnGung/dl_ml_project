{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import os\n",
    "from config import *\n",
    "from data_loader import *\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawngung/Desktop/offEval/data_loader.py:12: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  self.dataframe = pd.DataFrame.from_csv(file, sep='\\t', header=0)\n",
      "[nltk_data] Downloading package punkt to /Users/shawngung/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shawngung/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>stemmed_tweet</th>\n",
       "      <th>cleaned_s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86426</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ask, native, americans, take]</td>\n",
       "      <td>[ask, nativ, american, take]</td>\n",
       "      <td>ask native americans take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90194</th>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>[go, home, drunk, maga]</td>\n",
       "      <td>[go, home, drunk, maga]</td>\n",
       "      <td>go home drunk maga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16820</th>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[amazon, investigating, chinese, employees, se...</td>\n",
       "      <td>[amazon, investig, chines, employe, sell, inte...</td>\n",
       "      <td>amazon investigating chinese employees selling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62688</th>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[someone, havetaken, piece, shit, volcano]</td>\n",
       "      <td>[someon, havetaken, piec, shit, volcano]</td>\n",
       "      <td>someone havetaken piece shit volcano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43605</th>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[obama, wanted, liberals, amp, illegals, move,...</td>\n",
       "      <td>[obama, want, liber, amp, illeg, move, red, st...</td>\n",
       "      <td>obama wanted liberals amp illegals move red st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet subtask_a subtask_b  \\\n",
       "id                                                                             \n",
       "86426  @USER She should ask a few native Americans wh...       OFF       UNT   \n",
       "90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF       TIN   \n",
       "16820  Amazon is investigating Chinese employees who ...       NOT       NaN   \n",
       "62688  @USER Someone should'veTaken\" this piece of sh...       OFF       UNT   \n",
       "43605  @USER @USER Obama wanted liberals &amp; illega...       NOT       NaN   \n",
       "\n",
       "      subtask_c                                      cleaned_tweet  \\\n",
       "id                                                                   \n",
       "86426       NaN                     [ask, native, americans, take]   \n",
       "90194       IND                            [go, home, drunk, maga]   \n",
       "16820       NaN  [amazon, investigating, chinese, employees, se...   \n",
       "62688       NaN         [someone, havetaken, piece, shit, volcano]   \n",
       "43605       NaN  [obama, wanted, liberals, amp, illegals, move,...   \n",
       "\n",
       "                                           stemmed_tweet  \\\n",
       "id                                                         \n",
       "86426                       [ask, nativ, american, take]   \n",
       "90194                            [go, home, drunk, maga]   \n",
       "16820  [amazon, investig, chines, employe, sell, inte...   \n",
       "62688           [someon, havetaken, piec, shit, volcano]   \n",
       "43605  [obama, want, liber, amp, illeg, move, red, st...   \n",
       "\n",
       "                                               cleaned_s  \n",
       "id                                                        \n",
       "86426                          ask native americans take  \n",
       "90194                                 go home drunk maga  \n",
       "16820  amazon investigating chinese employees selling...  \n",
       "62688               someone havetaken piece shit volcano  \n",
       "43605  obama wanted liberals amp illegals move red st...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = Data_Loader()\n",
    "df = dl.get_data()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_percent = 0.8\n",
    "training_size = int(training_percent * total)\n",
    "validation_size = total - training_size\n",
    "\n",
    "corpus = df['cleaned_s'].values.copy()\n",
    "labels = df['subtask_a'].values.copy()\n",
    "labels[labels == 'OFF'] = 1\n",
    "labels[labels == 'NOT'] = 0\n",
    "\n",
    "labels = labels.astype(float)\n",
    "\n",
    "indices = list(range(total))\n",
    "np.random.shuffle(indices)\n",
    "training_sents = corpus[indices[:training_size]]\n",
    "training_labels = labels[indices[:training_size]]\n",
    "\n",
    "validation_sents = corpus[indices[training_size:]]\n",
    "validation_labels = labels[indices[training_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vec_training = vectorizer.fit_transform(training_sents)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=True)\n",
    "vec_training = tf_transformer.fit_transform(vec_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight={1.0: 2},\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={1.0: 2})\n",
    "\n",
    "clf.fit(vec_training, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_valid = tf_transformer.transform(vectorizer.transform(validation_sents))\n",
    "predictions = clf.predict(vec_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1669   53]\n",
      " [ 656  270]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "NOT OFFENSIVE       0.72      0.97      0.82      1722\n",
      "    OFFENSIVE       0.84      0.29      0.43       926\n",
      "\n",
      "    micro avg       0.73      0.73      0.73      2648\n",
      "    macro avg       0.78      0.63      0.63      2648\n",
      " weighted avg       0.76      0.73      0.69      2648\n",
      "\n",
      "Accuracy: 0.7322507552870091\n"
     ]
    }
   ],
   "source": [
    "target_names = ['NOT OFFENSIVE','OFFENSIVE']\n",
    "print(metrics.confusion_matrix(validation_labels, predictions))\n",
    "print(metrics.classification_report(validation_labels, predictions,target_names = target_names))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_b = df.count()['subtask_b'].item()\n",
    "training_percent = 0.8\n",
    "training_size = int(training_percent * total_b)\n",
    "validation_size = total_b - training_size\n",
    "\n",
    "train_b = df[df.subtask_a == 'OFF']\n",
    "corpus = train_b['cleaned_s'].values.copy()\n",
    "labels = train_b['subtask_b'].values.copy()\n",
    "labels[labels == 'TIN'] = 0\n",
    "labels[labels == 'UNT'] = 1\n",
    "labels = labels.astype(float)\n",
    "\n",
    "indices = list(range(total_b))\n",
    "np.random.shuffle(indices)\n",
    "training_sents = corpus[indices[:training_size]]\n",
    "training_labels = labels[indices[:training_size]]\n",
    "\n",
    "validation_sents = corpus[indices[training_size:]]\n",
    "validation_labels = labels[indices[training_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vec_training = vectorizer.fit_transform(training_sents)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=True)\n",
    "vec_training = tf_transformer.fit_transform(vec_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight={1.0: 6.8},\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={1.0: 6.8})\n",
    "\n",
    "clf.fit(vec_training, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_valid = tf_transformer.transform(vectorizer.transform(validation_sents))\n",
    "predictions = clf.predict(vec_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[631 129]\n",
      " [ 77  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      TARGET       0.89      0.83      0.86       760\n",
      "    UNTARGET       0.25      0.36      0.29       120\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       880\n",
      "   macro avg       0.57      0.59      0.58       880\n",
      "weighted avg       0.80      0.77      0.78       880\n",
      "\n",
      "Accuracy: 0.7659090909090909\n"
     ]
    }
   ],
   "source": [
    "target_names = ['TARGET','UNTARGET']\n",
    "print(metrics.confusion_matrix(validation_labels, predictions))\n",
    "print(metrics.classification_report(validation_labels, predictions,target_names=target_names))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset 3876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "total_c = df.count()['subtask_c'].item()\n",
    "training_percent = 0.8\n",
    "training_size = int(training_percent * total_c)\n",
    "validation_size = total_c - training_size\n",
    "\n",
    "train_c = df[df.subtask_a == 'OFF'][df.subtask_b == 'TIN']\n",
    "print(\"Size of dataset\", len(train_c))\n",
    "corpus = train_c['cleaned_s'].values.copy()\n",
    "labels = train_c['subtask_c'].values.copy()\n",
    "labels[labels == 'IND'] = 0\n",
    "labels[labels == 'GRP'] = 1\n",
    "labels[labels == 'OTH'] = 2\n",
    "labels = labels.astype(float)\n",
    "\n",
    "indices = list(range(total_c))\n",
    "np.random.shuffle(indices)\n",
    "training_sents = corpus[indices[:training_size]]\n",
    "training_labels = labels[indices[:training_size]]\n",
    "\n",
    "validation_sents = corpus[indices[training_size:]]\n",
    "validation_labels = labels[indices[training_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3100, 8302)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vec_training = vectorizer.fit_transform(training_sents)\n",
    "\n",
    "print(vec_training.shape)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=True)\n",
    "vec_training = tf_transformer.fit_transform(vec_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False,\n",
       "       class_weight={0: 1.6, 1: 3.7, 2: 8.4}, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
       "       random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={0:1.6, 1:3.7, 2:8.4})\n",
    "\n",
    "clf.fit(vec_training, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_valid = tf_transformer.transform(vectorizer.transform(validation_sents))\n",
    "predictions = clf.predict(vec_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[358  54  47]\n",
      " [ 87 132  24]\n",
      " [ 50  16   8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  INDIVIDUAL       0.72      0.78      0.75       459\n",
      "       GROUP       0.65      0.54      0.59       243\n",
      "       OTHER       0.10      0.11      0.10        74\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       776\n",
      "   macro avg       0.49      0.48      0.48       776\n",
      "weighted avg       0.64      0.64      0.64       776\n",
      "\n",
      "Accuracy: 0.6417525773195877\n"
     ]
    }
   ],
   "source": [
    "target_names = ['INDIVIDUAL','GROUP','OTHER']\n",
    "print(metrics.confusion_matrix(validation_labels, predictions))\n",
    "print(metrics.classification_report(validation_labels, predictions,target_names= target_names))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
